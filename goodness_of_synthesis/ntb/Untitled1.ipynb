{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf5660a-b6cd-4ab8-a49e-81025dbd8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "def make_latent_corr(kind=\"ar1\", rho=0.4, custom=None, seed=0):\n",
    "    \"\"\"\n",
    "    Return a 5x5 correlation matrix for the latent Gaussian copula.\n",
    "    kind = 'ar1' or 'custom'\n",
    "    - 'ar1': R_ij = rho^{|i-j|}\n",
    "    - 'custom': supply a valid SPD correlation in 'custom'\n",
    "    \"\"\"\n",
    "    d = 5\n",
    "    if kind == \"ar1\":\n",
    "        idx = np.arange(d)\n",
    "        R = rho ** np.abs(idx[:, None] - idx[None, :])\n",
    "        return R\n",
    "    elif kind == \"custom\":\n",
    "        if custom is None or custom.shape != (5, 5):\n",
    "            raise ValueError(\"Provide a 5x5 custom correlation matrix.\")\n",
    "        # Basic checks\n",
    "        if not np.allclose(np.diag(custom), 1.0, atol=1e-8):\n",
    "            raise ValueError(\"Custom correlation must have ones on the diagonal.\")\n",
    "        # Symmetrize and nudge to SPD if needed\n",
    "        R = 0.5 * (custom + custom.T)\n",
    "        # Attempt a Cholesky to ensure SPD; if it fails, nudge eigenvalues\n",
    "        try:\n",
    "            np.linalg.cholesky(R)\n",
    "        except np.linalg.LinAlgError:\n",
    "            w, V = np.linalg.eigh(R)\n",
    "            w = np.clip(w, 1e-6, None)\n",
    "            R = (V * w) @ V.T\n",
    "            R = R / np.sqrt(np.outer(np.diag(R), np.diag(R)))  # renormalize to correlation\n",
    "        return R\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'ar1' or 'custom'.\")\n",
    "\n",
    "def make_thresholds_from_probs(category_probs):\n",
    "    \"\"\"\n",
    "    Convert a list of category probability vectors into latent normal thresholds.\n",
    "    For each variable j, category_probs[j] is a list summing to 1 (e.g., [0.2,0.5,0.3]).\n",
    "    Returns a list of arrays of cutpoints including +/- inf for convenience.\n",
    "    \"\"\"\n",
    "    thresholds = []\n",
    "    for probs in category_probs:\n",
    "        cdf = np.cumsum(probs)\n",
    "        if not np.isclose(cdf[-1], 1.0):\n",
    "            raise ValueError(\"Category probabilities must sum to 1 for each variable.\")\n",
    "        # internal cutpoints are inverse-normal of cumulative probs (excluding final 1.0)\n",
    "        inner = norm.ppf(cdf[:-1])\n",
    "        thr = np.concatenate(([-np.inf], inner, [np.inf]))\n",
    "        thresholds.append(thr)\n",
    "    return thresholds\n",
    "\n",
    "def sample_categorical_gaussian_copula(n, R, category_probs, seed=123):\n",
    "    \"\"\"\n",
    "    Generate n samples of 5 categorical variables via a Gaussian copula:\n",
    "    1) Z ~ N(0, R)\n",
    "    2) X_j = discretize(Z_j) using thresholds implied by category_probs[j]\n",
    "    Returns a pandas DataFrame with categorical dtype.\n",
    "    \"\"\"\n",
    "    d = 5\n",
    "    if len(category_probs) != d:\n",
    "        raise ValueError(\"Provide category_probs for exactly 5 variables.\")\n",
    "    # Cholesky\n",
    "    L = np.linalg.cholesky(R)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = rng.standard_normal((n, d)) @ L.T\n",
    "\n",
    "    thresholds = make_thresholds_from_probs(category_probs)\n",
    "    X = np.zeros((n, d), dtype=int)\n",
    "    for j in range(d):\n",
    "        thr = thresholds[j]\n",
    "        # np.digitize returns bin index where Z falls; use right=False so bins are (-inf, t1], (t1, t2], ...\n",
    "        # but we constructed thr with +/-inf, so we use searchsorted on thr to find category.\n",
    "        # Category k if thr[k] < Z <= thr[k+1]; equivalently searchsorted(thr, Z, side='right') - 1\n",
    "        X[:, j] = np.searchsorted(thr, Z[:, j], side='right') - 1\n",
    "\n",
    "    # Make a DataFrame with categorical dtype\n",
    "    df = pd.DataFrame({f\"V{j+1}\": pd.Categorical(X[:, j]) for j in range(d)})\n",
    "    return df\n",
    "\n",
    "def one_hot_covariance(df):\n",
    "    \"\"\"\n",
    "    Compute covariance of one-hot encodings for each column, concatenated.\n",
    "    Returns covariance matrix and column labels for the one-hot matrix.\n",
    "    \"\"\"\n",
    "    oh_blocks = []\n",
    "    labels = []\n",
    "    for col in df.columns:\n",
    "        cats = df[col].cat.categories\n",
    "        # get_dummies will produce uint8; cast to float\n",
    "        O = pd.get_dummies(df[col], prefix=col).astype(float)\n",
    "        oh_blocks.append(O)\n",
    "        labels.extend(list(O.columns))\n",
    "    O_all = pd.concat(oh_blocks, axis=1)\n",
    "    cov = np.cov(O_all.values, rowvar=False)\n",
    "    return cov, labels\n",
    "\n",
    "\n",
    "\n",
    "def integer_covariance(df):\n",
    "    \"\"\"\n",
    "    Covariance of integer-coded categories (0..K-1 per variable).\n",
    "    \"\"\"\n",
    "    X_int = np.column_stack([df[c].cat.codes for c in df.columns])\n",
    "    return np.cov(X_int, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b112d4-4068-4072-8ca6-4c020ba5c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent correlation (target) R:\n",
      "[[1.    0.6   0.36  0.216 0.13 ]\n",
      " [0.6   1.    0.6   0.36  0.216]\n",
      " [0.36  0.6   1.    0.6   0.36 ]\n",
      " [0.216 0.36  0.6   1.    0.6  ]\n",
      " [0.13  0.216 0.36  0.6   1.   ]]\n",
      "\n",
      "Empirical covariance (integer-coded categories):\n",
      "[[0.493 0.339 0.088 0.093 0.029]\n",
      " [0.339 0.979 0.202 0.233 0.078]\n",
      " [0.088 0.202 0.241 0.169 0.055]\n",
      " [0.093 0.233 0.169 0.679 0.185]\n",
      " [0.029 0.078 0.055 0.185 0.247]]\n",
      "\n",
      "Empirical covariance (one-hot encoding) shape: (14, 14)\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Example usage ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    n = 10000\n",
    "\n",
    "    # Choose how to \"specify the covariance matrix\" of the latent Gaussian:\n",
    "    # Option A: AR(1) with rho\n",
    "    R = make_latent_corr(kind=\"ar1\", rho=0.6)\n",
    "\n",
    "    # Option B: Custom correlation (uncomment to use)\n",
    "    # custom_R = np.array([\n",
    "    #     [1.00, 0.35, 0.10, 0.00, -0.20],\n",
    "    #     [0.35, 1.00, 0.25, 0.05,  0.00],\n",
    "    #     [0.10, 0.25, 1.00, 0.40,  0.10],\n",
    "    #     [0.00, 0.05, 0.40, 1.00,  0.30],\n",
    "    #     [-0.20, 0.00, 0.10, 0.30, 1.00]\n",
    "    # ])\n",
    "    # R = make_latent_corr(kind=\"custom\", custom=custom_R)\n",
    "\n",
    "    # Specify category counts and (optionally) marginal probabilities per variable.\n",
    "    # Here: V1 has 3 categories, V2 has 4, others have 2/3 as examples.\n",
    "    # You can set any probs; they must sum to 1 per variable.\n",
    "    category_probs = [\n",
    "        [0.2, 0.5, 0.3],        # V1 (3 categories)\n",
    "        [0.1, 0.2, 0.3, 0.4],   # V2 (4 categories)\n",
    "        [0.6, 0.4],             # V3 (2 categories)\n",
    "        [0.25, 0.25, 0.5],      # V4 (3 categories)\n",
    "        [0.45, 0.55]            # V5 (2 categories)\n",
    "    ]\n",
    "\n",
    "    # Sample categorical data\n",
    "    df_cat = sample_categorical_gaussian_copula(n=n, R=R, category_probs=category_probs, seed=123)\n",
    "\n",
    "    # Empirical covariance of integer-coded categories (0..K-1)\n",
    "    cov_int = integer_covariance(df_cat)\n",
    "\n",
    "    # Empirical covariance of the one-hot representation (block structure)\n",
    "    cov_oh, oh_labels = one_hot_covariance(df_cat)\n",
    "\n",
    "    # Quick summaries\n",
    "    print(\"Latent correlation (target) R:\")\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(R)\n",
    "\n",
    "    print(\"\\nEmpirical covariance (integer-coded categories):\")\n",
    "    print(cov_int)\n",
    "\n",
    "    print(\"\\nEmpirical covariance (one-hot encoding) shape:\", cov_oh.shape)\n",
    "    # If you want to see the one-hot cov, uncomment:\n",
    "    # print(pd.DataFrame(cov_oh, index=oh_labels, columns=oh_labels).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90030c4e-6b71-4932-86b3-ce7f1d0bdb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1 V2 V3 V4 V5\n",
       "0     0  1  1  2  1\n",
       "1     2  2  1  1  0\n",
       "2     1  1  1  1  1\n",
       "3     1  3  1  1  1\n",
       "4     0  1  1  2  1\n",
       "...  .. .. .. .. ..\n",
       "9995  2  3  1  2  1\n",
       "9996  1  2  0  2  1\n",
       "9997  0  2  0  2  1\n",
       "9998  0  0  1  2  1\n",
       "9999  0  1  0  0  0\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f58daf-dbb1-4c22-9c07-990af46f3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, chi2\n",
    "# If you prefer a mixture instead of t, you don't need scipy\n",
    "\n",
    "def make_covariance(d=15, kind=\"ar1\", rho=0.5, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if kind == \"ar1\":\n",
    "        i = np.arange(d)\n",
    "        R = rho ** np.abs(i[:,None] - i[None,:])  # correlation\n",
    "        stds = rng.uniform(0.8, 1.6, size=d)\n",
    "        S = np.diag(stds)\n",
    "        return S @ R @ S\n",
    "    elif kind == \"random_spd\":\n",
    "        A = rng.standard_normal((d,d))\n",
    "        Q, _ = np.linalg.qr(A)\n",
    "        eigs = (0.7 ** np.arange(d))\n",
    "        eigs = eigs / np.mean(eigs)\n",
    "        target_var = 1.2\n",
    "        eigs = eigs * target_var\n",
    "        Sig = Q @ np.diag(eigs) @ Q.T\n",
    "        return 0.5*(Sig+Sig.T)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "def sample_gaussian(n, mu, cov, rng):\n",
    "    return rng.multivariate_normal(mu, cov, size=n)\n",
    "\n",
    "def sample_student_t(n, mu, cov, df, rng):\n",
    "    # Draw Z ~ N(0, cov), W ~ chi2_df; T = mu + Z / sqrt(W/df)\n",
    "    L = np.linalg.cholesky(cov)\n",
    "    Z = rng.standard_normal((n, cov.shape[0])) @ L.T\n",
    "    W = rng.chisquare(df, size=n)\n",
    "    return mu + Z / np.sqrt(W/df)[:,None]\n",
    "\n",
    "def sample_gaussian_mixture(n, mu, cov, rng, n_comp=3, shift_scale=2.5):\n",
    "    # Same base covariance in each component, different means to create multimodality\n",
    "    d = cov.shape[0]\n",
    "    L = np.linalg.cholesky(cov)\n",
    "    means = rng.standard_normal((n_comp, d)) * shift_scale\n",
    "    pi = rng.dirichlet(np.ones(n_comp))\n",
    "    comps = rng.choice(n_comp, size=n, p=pi)\n",
    "    X = np.empty((n,d))\n",
    "    for k in range(n_comp):\n",
    "        idx = np.where(comps==k)[0]\n",
    "        if idx.size:\n",
    "            Z = rng.standard_normal((idx.size, d)) @ L.T\n",
    "            X[idx] = means[k] + Z\n",
    "    return X\n",
    "\n",
    "def recolor_to_target_cov(X, Sigma_target):\n",
    "    \"\"\"\n",
    "    Linear transform X so that its *sample* covariance equals Sigma_target exactly.\n",
    "    Let S = sample_cov(X). Then X' = A (X - mean) + m, with A = L_t @ inv(L_s),\n",
    "    where L_t L_t^T = Sigma_target, L_s L_s^T = S.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    m = X.mean(axis=0)\n",
    "    Xc = X - m\n",
    "    S = np.cov(Xc, rowvar=False, bias=False)  # d x d\n",
    "    Ls = np.linalg.cholesky(S)\n",
    "    Lt = np.linalg.cholesky(Sigma_target)\n",
    "    A = Lt @ np.linalg.inv(Ls)\n",
    "    X_new = Xc @ A.T + m  # add back mean; means can differ arbitrarily\n",
    "    # Numerically, the sample covariance of X_new is ~ Sigma_target\n",
    "    return X_new\n",
    "\n",
    "def summarize(name, X):\n",
    "    emp_cov = np.cov(X, rowvar=False)\n",
    "    d = X.shape[1]\n",
    "    tail = (np.linalg.norm((X - X.mean(0)) / X.std(0, ddof=1), axis=1) > 3).mean()\n",
    "    krt = kurtosis(X, axis=0, fisher=True, bias=False)  # per-dim excess kurtosis\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"  mean variance (trace/d):\", np.trace(emp_cov)/d)\n",
    "    print(\"  average excess kurtosis:\", float(np.mean(krt)))\n",
    "    print(\"  fraction of samples with z-norm > 3:\", float(tail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fabf815-090b-4559-a9c5-8de23bedddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max |Cov_G - Cov_T|: 8.881784197001252e-16\n",
      "Max |Cov_G - Sigma_target|: 8.881784197001252e-16\n",
      "Max |Cov_T - Sigma_target|: 1.7763568394002505e-15\n",
      "\n",
      "Gaussian (recolored):\n",
      "  mean variance (trace/d): 1.707547709515343\n",
      "  average excess kurtosis: 0.01933380811425452\n",
      "  fraction of samples with z-norm > 3: 0.806125\n",
      "\n",
      "Student-t df=5 (recolored):\n",
      "  mean variance (trace/d): 1.7075477095153433\n",
      "  average excess kurtosis: 3.615264183179276\n",
      "  fraction of samples with z-norm > 3: 0.541875\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.default_rng(123)\n",
    "    n, d = 8000, 15\n",
    "\n",
    "    # 1) Choose a target covariance you want both datasets to share\n",
    "    Sigma_target = make_covariance(d=d, kind=\"ar1\", rho=0.5, seed=42)\n",
    "\n",
    "    # 2) Create two *different* base datasets\n",
    "    #    A: Gaussian\n",
    "    Xg_base = sample_gaussian(n, mu=np.zeros(d), cov=np.eye(d), rng=rng)\n",
    "\n",
    "    #    B: heavy-tailed t (df=5)  [Alternative: use sample_gaussian_mixture(...)]\n",
    "    Xt_base = sample_student_t(n, mu=np.zeros(d), cov=np.eye(d), df=5, rng=rng)\n",
    "    # Or try: Xt_base = sample_gaussian_mixture(n, np.zeros(d), np.eye(d), rng, n_comp=3)\n",
    "\n",
    "    # 3) Recolor both to have the SAME sample covariance = Sigma_target\n",
    "    Xg = recolor_to_target_cov(Xg_base, Sigma_target)\n",
    "    Xt = recolor_to_target_cov(Xt_base, Sigma_target)\n",
    "\n",
    "    # 4) Verify: the two sample covariances are (numerically) identical to Sigma_target\n",
    "    cov_g = np.cov(Xg, rowvar=False)\n",
    "    cov_t = np.cov(Xt, rowvar=False)\n",
    "\n",
    "    print(\"Max |Cov_G - Cov_T|:\", float(np.max(np.abs(cov_g - cov_t))))\n",
    "    print(\"Max |Cov_G - Sigma_target|:\", float(np.max(np.abs(cov_g - Sigma_target))))\n",
    "    print(\"Max |Cov_T - Sigma_target|:\", float(np.max(np.abs(cov_t - Sigma_target))))\n",
    "\n",
    "    # 5) Show they differ substantially in other statistics\n",
    "    summarize(\"Gaussian (recolored)\", Xg)\n",
    "    summarize(\"Student-t df=5 (recolored)\", Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a38061-9681-4574-8dcf-b67117a495f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.423, -0.952,  1.069, ...,  0.477, -0.639,  0.752],\n",
       "       [ 0.185,  1.579,  0.141, ...,  2.166,  1.674,  0.787],\n",
       "       [-0.527, -1.439,  0.681, ...,  1.232,  0.456, -0.453],\n",
       "       ...,\n",
       "       [-0.578,  0.578, -0.086, ...,  0.583, -0.167, -1.04 ],\n",
       "       [-0.498, -1.687, -2.929, ...,  0.008, -1.73 , -0.916],\n",
       "       [-1.381,  1.661,  0.196, ...,  2.417,  0.235, -1.024]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f704b3db-2af2-4b7f-b319-55eaac8cdc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.721,  0.045,  1.113, ...,  0.643, -0.363,  0.048],\n",
       "       [-0.751,  0.329,  0.387, ..., -0.04 , -0.039,  1.143],\n",
       "       [ 2.933,  0.555, -0.73 , ..., -0.754, -1.22 , -2.189],\n",
       "       ...,\n",
       "       [-1.278,  0.265, -3.9  , ...,  0.853,  4.332,  0.331],\n",
       "       [-1.555, -0.748, -0.485, ..., -0.087,  1.464,  1.892],\n",
       "       [-1.614,  0.173, -1.048, ..., -1.295, -2.03 , -1.135]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e2ca47-e593-44e5-bac2-f0b725aa83da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.023547\n",
       "1     0.004922\n",
       "2    -0.011737\n",
       "3     0.021344\n",
       "4     0.008978\n",
       "5     0.006381\n",
       "6    -0.022074\n",
       "7     0.003173\n",
       "8    -0.024061\n",
       "9    -0.011829\n",
       "10   -0.002408\n",
       "11    0.001171\n",
       "12    0.007928\n",
       "13   -0.002583\n",
       "14   -0.011554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27ac8809-acf3-4c5b-b899-fac4b8c8ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xt).to_csv('xt.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c577f121-058d-4562-80e7-381cb163f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xg).to_csv('xg.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05a437-8e82-49bb-8cd7-948559af1e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
